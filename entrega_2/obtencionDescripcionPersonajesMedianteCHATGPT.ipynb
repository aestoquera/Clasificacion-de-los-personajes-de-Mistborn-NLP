{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a concatenar todos los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del DataFrame concatenado: (16037, 4)\n",
      "               Name                                Subcategory  MBTI Eneagram\n",
      "0     Enid Sinclair                           Wednesday (2022)  ESFP      7w6\n",
      "1        Misa Amane                                 Death Note  ESFP      2w3\n",
      "2       Gon Freecss                            Hunter X Hunter  ESFP      8w7\n",
      "3  Nikocado Avocado  Health, Food, Beauty, Fashion & Lifestyle  ESFP      7w6\n",
      "4     Jesse Pinkman                        Breaking Bad (2008)  ESFP      6w7\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directorio de los archivos Excel\n",
    "directorioExcelsPersonalidad = \"../Datasets/pdb_characters_labeled/\"\n",
    "\n",
    "# Lista para almacenar los DataFrames de cada archivo Excel\n",
    "dataframes = []\n",
    "\n",
    "# Obtener la lista de archivos en el directorio\n",
    "archivos = os.listdir(directorioExcelsPersonalidad)\n",
    "#print(archivos)\n",
    "\n",
    "# Iterar a trav√©s de cada archivo en el directorio\n",
    "for archivo in archivos:\n",
    "    if archivo.endswith('.csv'):\n",
    "        # Leer cada archivo Excel y convertirlo a DataFrame\n",
    "        ruta_archivo = os.path.join(directorioExcelsPersonalidad, archivo)\n",
    "        df = pd.read_csv(ruta_archivo)\n",
    "        # Agregar el DataFrame a la lista\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Concatenar todos los DataFrames en uno\n",
    "df_concatenado = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Mostrar la forma del DataFrame resultante\n",
    "print(\"Forma del DataFrame concatenado:\", df_concatenado.shape)\n",
    "\n",
    "# Visualizar las primeras filas del DataFrame concatenado\n",
    "print(df_concatenado.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crearPrompt(row):\n",
    "    prompt = f\"Descripcion personalidad {row['Name']} de {row['Subcategory']}\"\n",
    "    return prompt\n",
    "\n",
    "# Aplicar la funci√≥n crearPrompt a cada fila del DataFrame utilizando axis=1 para aplicarlo a las filas\n",
    "df_concatenado[\"Prompt\"] = df_concatenado.apply(crearPrompt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Subcategory</th>\n",
       "      <th>MBTI</th>\n",
       "      <th>Eneagram</th>\n",
       "      <th>Prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enid Sinclair</td>\n",
       "      <td>Wednesday (2022)</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>7w6</td>\n",
       "      <td>Descripcion personalidad Enid Sinclair de Wedn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Misa Amane</td>\n",
       "      <td>Death Note</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>2w3</td>\n",
       "      <td>Descripcion personalidad Misa Amane de Death Note</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gon Freecss</td>\n",
       "      <td>Hunter X Hunter</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>8w7</td>\n",
       "      <td>Descripcion personalidad Gon Freecss de Hunter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nikocado Avocado</td>\n",
       "      <td>Health, Food, Beauty, Fashion &amp; Lifestyle</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>7w6</td>\n",
       "      <td>Descripcion personalidad Nikocado Avocado de H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jesse Pinkman</td>\n",
       "      <td>Breaking Bad (2008)</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>6w7</td>\n",
       "      <td>Descripcion personalidad Jesse Pinkman de Brea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name                                Subcategory  MBTI Eneagram  \\\n",
       "0     Enid Sinclair                           Wednesday (2022)  ESFP      7w6   \n",
       "1        Misa Amane                                 Death Note  ESFP      2w3   \n",
       "2       Gon Freecss                            Hunter X Hunter  ESFP      8w7   \n",
       "3  Nikocado Avocado  Health, Food, Beauty, Fashion & Lifestyle  ESFP      7w6   \n",
       "4     Jesse Pinkman                        Breaking Bad (2008)  ESFP      6w7   \n",
       "\n",
       "                                              Prompt  \n",
       "0  Descripcion personalidad Enid Sinclair de Wedn...  \n",
       "1  Descripcion personalidad Misa Amane de Death Note  \n",
       "2  Descripcion personalidad Gon Freecss de Hunter...  \n",
       "3  Descripcion personalidad Nikocado Avocado de H...  \n",
       "4  Descripcion personalidad Jesse Pinkman de Brea...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concatenado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ëPeticion info a ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porfa no me roveis la clave :D\n",
    "from openai import OpenAI\n",
    "def getDescripcion(prompt):\n",
    "    client = OpenAI(\n",
    "        #api_key='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'\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"text-curie-001\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    )\n",
    "\n",
    "\n",
    "    return(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_concatenado.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mg:\\.shortcut-targets-by-id\\1tbwtJBZplHfm91lceTlpEA9t4RR96dyM\\NLP Grupo\\Codigo\\obtencionDescripcionPersonajesMedianteCHATGPT.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/.shortcut-targets-by-id/1tbwtJBZplHfm91lceTlpEA9t4RR96dyM/NLP%20Grupo/Codigo/obtencionDescripcionPersonajesMedianteCHATGPT.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Iterar a trav√©s de las filas del DataFrame y aplicar la funci√≥n getDescripcion\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/.shortcut-targets-by-id/1tbwtJBZplHfm91lceTlpEA9t4RR96dyM/NLP%20Grupo/Codigo/obtencionDescripcionPersonajesMedianteCHATGPT.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m df_test\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/.shortcut-targets-by-id/1tbwtJBZplHfm91lceTlpEA9t4RR96dyM/NLP%20Grupo/Codigo/obtencionDescripcionPersonajesMedianteCHATGPT.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     respuesta \u001b[39m=\u001b[39m getDescripcion(row[\u001b[39m'\u001b[39;49m\u001b[39mPrompt\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/.shortcut-targets-by-id/1tbwtJBZplHfm91lceTlpEA9t4RR96dyM/NLP%20Grupo/Codigo/obtencionDescripcionPersonajesMedianteCHATGPT.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     respuestas\u001b[39m.\u001b[39mappend(respuesta)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/.shortcut-targets-by-id/1tbwtJBZplHfm91lceTlpEA9t4RR96dyM/NLP%20Grupo/Codigo/obtencionDescripcionPersonajesMedianteCHATGPT.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Agregar las respuestas al DataFrame en una nueva columna 'Respuesta'\u001b[39;00m\n",
      "\u001b[1;32mg:\\.shortcut-targets-by-id\\1tbwtJBZplHfm91lceTlpEA9t4RR96dyM\\NLP Grupo\\Codigo\\obtencionDescripcionPersonajesMedianteCHATGPT.ipynb Cell 8\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/.shortcut-targets-by-id/1tbwtJBZplHfm91lceTlpEA9t4RR96dyM/NLP%20Grupo/Codigo/obtencionDescripcionPersonajesMedianteCHATGPT.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetDescripcion\u001b[39m(prompt):\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/.shortcut-targets-by-id/1tbwtJBZplHfm91lceTlpEA9t4RR96dyM/NLP%20Grupo/Codigo/obtencionDescripcionPersonajesMedianteCHATGPT.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     client \u001b[39m=\u001b[39m OpenAI(\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/.shortcut-targets-by-id/1tbwtJBZplHfm91lceTlpEA9t4RR96dyM/NLP%20Grupo/Codigo/obtencionDescripcionPersonajesMedianteCHATGPT.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         api_key\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msk-IWzNT7dNCaNhadURZMvgT3BlbkFJ9rpI5RCdSfsioeUYgesh\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/.shortcut-targets-by-id/1tbwtJBZplHfm91lceTlpEA9t4RR96dyM/NLP%20Grupo/Codigo/obtencionDescripcionPersonajesMedianteCHATGPT.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     )\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/.shortcut-targets-by-id/1tbwtJBZplHfm91lceTlpEA9t4RR96dyM/NLP%20Grupo/Codigo/obtencionDescripcionPersonajesMedianteCHATGPT.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mchat\u001b[39m.\u001b[39;49mcompletions\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/.shortcut-targets-by-id/1tbwtJBZplHfm91lceTlpEA9t4RR96dyM/NLP%20Grupo/Codigo/obtencionDescripcionPersonajesMedianteCHATGPT.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext-curie-001\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/.shortcut-targets-by-id/1tbwtJBZplHfm91lceTlpEA9t4RR96dyM/NLP%20Grupo/Codigo/obtencionDescripcionPersonajesMedianteCHATGPT.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     messages\u001b[39m=\u001b[39;49m[\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/.shortcut-targets-by-id/1tbwtJBZplHfm91lceTlpEA9t4RR96dyM/NLP%20Grupo/Codigo/obtencionDescripcionPersonajesMedianteCHATGPT.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt}\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/.shortcut-targets-by-id/1tbwtJBZplHfm91lceTlpEA9t4RR96dyM/NLP%20Grupo/Codigo/obtencionDescripcionPersonajesMedianteCHATGPT.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/.shortcut-targets-by-id/1tbwtJBZplHfm91lceTlpEA9t4RR96dyM/NLP%20Grupo/Codigo/obtencionDescripcionPersonajesMedianteCHATGPT.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/.shortcut-targets-by-id/1tbwtJBZplHfm91lceTlpEA9t4RR96dyM/NLP%20Grupo/Codigo/obtencionDescripcionPersonajesMedianteCHATGPT.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m(response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage)\n",
      "File \u001b[1;32mc:\\Users\\aesto\\anaconda3\\envs\\NLP\\Lib\\site-packages\\openai\\_utils\\_utils.py:299\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 299\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aesto\\anaconda3\\envs\\NLP\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:449\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, max_tokens, n, presence_penalty, stop, stream, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    410\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    411\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    447\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    448\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatCompletion \u001b[39m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[0;32m    450\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/chat/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    451\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[0;32m    452\u001b[0m             {\n\u001b[0;32m    453\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmessages\u001b[39;49m\u001b[39m\"\u001b[39;49m: messages,\n\u001b[0;32m    454\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[0;32m    455\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: frequency_penalty,\n\u001b[0;32m    456\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunction_call\u001b[39;49m\u001b[39m\"\u001b[39;49m: function_call,\n\u001b[0;32m    457\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunctions\u001b[39;49m\u001b[39m\"\u001b[39;49m: functions,\n\u001b[0;32m    458\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogit_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m: logit_bias,\n\u001b[0;32m    459\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens,\n\u001b[0;32m    460\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m: n,\n\u001b[0;32m    461\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: presence_penalty,\n\u001b[0;32m    462\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop,\n\u001b[0;32m    463\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[0;32m    464\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[0;32m    465\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[0;32m    466\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m: user,\n\u001b[0;32m    467\u001b[0m             },\n\u001b[0;32m    468\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParams,\n\u001b[0;32m    469\u001b[0m         ),\n\u001b[0;32m    470\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[0;32m    471\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[0;32m    472\u001b[0m         ),\n\u001b[0;32m    473\u001b[0m         cast_to\u001b[39m=\u001b[39;49mChatCompletion,\n\u001b[0;32m    474\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    475\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[ChatCompletionChunk],\n\u001b[0;32m    476\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aesto\\anaconda3\\envs\\NLP\\Lib\\site-packages\\openai\\_base_client.py:1055\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[0;32m   1042\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1043\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1050\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1051\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m   1052\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[0;32m   1053\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[0;32m   1054\u001b[0m     )\n\u001b[1;32m-> 1055\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[1;32mc:\\Users\\aesto\\anaconda3\\envs\\NLP\\Lib\\site-packages\\openai\\_base_client.py:834\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    826\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    827\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    832\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    833\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m--> 834\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    835\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    836\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    837\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    838\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    839\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[0;32m    840\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aesto\\anaconda3\\envs\\NLP\\Lib\\site-packages\\openai\\_base_client.py:865\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mHTTPStatusError \u001b[39mas\u001b[39;00m err:  \u001b[39m# thrown on 4xx and 5xx status code\u001b[39;00m\n\u001b[0;32m    864\u001b[0m     \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[1;32m--> 865\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[0;32m    866\u001b[0m             options,\n\u001b[0;32m    867\u001b[0m             cast_to,\n\u001b[0;32m    868\u001b[0m             retries,\n\u001b[0;32m    869\u001b[0m             err\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    870\u001b[0m             stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    871\u001b[0m             stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    872\u001b[0m         )\n\u001b[0;32m    874\u001b[0m     \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    875\u001b[0m     \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Users\\aesto\\anaconda3\\envs\\NLP\\Lib\\site-packages\\openai\\_base_client.py:925\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m    923\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[1;32m--> 925\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    926\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    927\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    928\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[0;32m    929\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    930\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    931\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aesto\\anaconda3\\envs\\NLP\\Lib\\site-packages\\openai\\_base_client.py:865\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mHTTPStatusError \u001b[39mas\u001b[39;00m err:  \u001b[39m# thrown on 4xx and 5xx status code\u001b[39;00m\n\u001b[0;32m    864\u001b[0m     \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[1;32m--> 865\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[0;32m    866\u001b[0m             options,\n\u001b[0;32m    867\u001b[0m             cast_to,\n\u001b[0;32m    868\u001b[0m             retries,\n\u001b[0;32m    869\u001b[0m             err\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    870\u001b[0m             stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    871\u001b[0m             stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    872\u001b[0m         )\n\u001b[0;32m    874\u001b[0m     \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    875\u001b[0m     \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Users\\aesto\\anaconda3\\envs\\NLP\\Lib\\site-packages\\openai\\_base_client.py:925\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m    923\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[1;32m--> 925\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    926\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    927\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    928\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[0;32m    929\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    930\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    931\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aesto\\anaconda3\\envs\\NLP\\Lib\\site-packages\\openai\\_base_client.py:877\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    874\u001b[0m     \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    875\u001b[0m     \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[1;32m--> 877\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_status_error_from_response(err\u001b[39m.\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    879\u001b[0m     \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "# Crear una lista vac√≠a para almacenar las respuestas\n",
    "respuestas = []\n",
    "\n",
    "# Iterar a trav√©s de las filas del DataFrame y aplicar la funci√≥n getDescripcion\n",
    "for index, row in df_test.iterrows():\n",
    "    respuesta = getDescripcion(row['Prompt'])\n",
    "    respuestas.append(respuesta)\n",
    "\n",
    "# Agregar las respuestas al DataFrame en una nueva columna 'Respuesta'\n",
    "df_test['Respuesta'] = respuestas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
